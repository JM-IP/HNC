[DEFAULT]
downsample_type = A

########### FLOAT NETWORK - RETRAINED ###########
[DEFAULT_]
lr = 0.03

[DEFAULT_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.03

[DEFAULT_RLR]
lr = 0.01

[DEFAULT_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01

########### STATIC FIXED-POINT QUANTIZATION (CONSTRAINED) ###########

[FP]
lr = 0.01

[FP_W2Q_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.03
w_quantize = fp
w_bitwidth = 2

[FP_W2A4Q_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.03
w_quantize = fp
w_bitwidth = 2
a_quantize = fp_relu
a_bitwidth = 4


[FP_W2Q_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = fp
w_bitwidth = 2

[FP_W2A4Q_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = fp
w_bitwidth = 2
a_quantize = fp_relu
a_bitwidth = 4


[FP_W2Q_INIT_RRLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = fp
w_bitwidth = 2

[FP_W2A4Q_INIT_RRLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = fp
w_bitwidth = 2
a_quantize = fp_relu
a_bitwidth = 4

########### PARAMETRIC FIXED-POINT QUANTIZATION (UNCONSTRAINED) ###########



[PARAMETRIC_FP_WQ_B_XMAX]
lr = 0.03
w_quantize = parametric_fp_b_xmax

[PARAMETRIC_FP_WQ_B_XMAX_INIT]
lr = 0.003
w_quantize = parametric_fp_b_xmax
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7

[PARAMETRIC_FP_WQ_DELTA_B]
lr = 0.03
w_quantize = parametric_fp_d_b

[PARAMETRIC_FP_WAQ_B_XMAX]
lr = 0.03
w_quantize = parametric_fp_b_xmax
a_quantize = parametric_fp_b_xmax_relu

[PARAMETRIC_FP_WAQ_DELTA_B]
lr = 0.03
w_quantize = parametric_fp_d_b
a_quantize = parametric_fp_d_b_relu

[PARAMETRIC_FP_WQ_DELTA_XMAX]
lr = 0.03
w_quantize = parametric_fp_d_xmax

[PARAMETRIC_FP_WQ_DELTA_XMAX_DR]
lr = 0.003
w_quantize = parametric_fp_d_xmax

[PARAMETRIC_FP_WQ_DELTA_XMAX_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.03
w_quantize = parametric_fp_d_xmax

[PARAMETRIC_FP_WQ_DELTA_XMAX_INIT_DR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_d_xmax

[PARAMETRIC_FP_WAQ_DELTA_XMAX_MobileNet]
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
;a_stepsize = 0.03125
w_bitwidth = 8
a_bitwidth = 8

[PARAMETRIC_FP_WAQ_DELTA_XMAX_MobileNet16bit]
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_stepsize = 0.015625
w_bitwidth = 16
a_bitwidth = 16
w_stepsize=0.0625

[PARAMETRIC_FP_WAQ_DELTA_XMAX]
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu

[PARAMETRIC_FP_WAQ_DELTA_XMAX_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.03
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu

[PARAMETRIC_FP_WAQ_DELTA_XMAX_INIT_DR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu

[PARAMETRIC_FP_WQ_DELTA_B_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.03
w_quantize = parametric_fp_d_b


[PARAMETRIC_FP_WAQ_B_XMAX_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.03
w_quantize = parametric_fp_b_xmax
a_quantize = parametric_fp_b_xmax_relu

[PARAMETRIC_FP_WAQ_DELTA_B_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.03
w_quantize = parametric_fp_d_b
a_quantize = parametric_fp_d_b_relu


[PARAMETRIC_FP_WQ_DELTA_XMAX_RLR]
lr = 0.01
w_quantize = parametric_fp_d_xmax

[PARAMETRIC_FP_WQ_B_XMAX_RLR]
lr = 0.01
w_quantize = parametric_fp_b_xmax

[PARAMETRIC_FP_WQ_DELTA_B_RLR]
lr = 0.01
w_quantize = parametric_fp_d_b

[PARAMETRIC_FP_WAQ_DELTA_XMAX_RLR]
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu

[PARAMETRIC_FP_WAQ_B_XMAX_RLR]
lr = 0.01
w_quantize = parametric_fp_b_xmax
a_quantize = parametric_fp_b_xmax_relu

[PARAMETRIC_FP_WAQ_DELTA_B_RLR]
lr = 0.01
w_quantize = parametric_fp_d_b
a_quantize = parametric_fp_d_b_relu


[PARAMETRIC_FP_WQ_DELTA_XMAX_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax

[PARAMETRIC_FP_WQ_B_XMAX_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_b_xmax

[PARAMETRIC_FP_WQ_DELTA_B_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_b

[PARAMETRIC_FP_WAQ_DELTA_XMAX_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu

[PARAMETRIC_FP_WAQ_B_XMAX_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_b_xmax
a_quantize = parametric_fp_b_xmax_relu

[PARAMETRIC_FP_WAQ_DELTA_B_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_b
a_quantize = parametric_fp_d_b_relu


########### PARAMETRIC FIXED-POINT QUANTIZATION WITH ADAM (UNCONSTRAINED) ###########

[PARAMETRIC_FP_WQ_DELTA_XMAX_INIT_ADAM] #app66/0
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
optimizer = adam
lr = 0.001
w_quantize = parametric_fp_d_xmax

[PARAMETRIC_FP_WQ_B_XMAX_INIT_ADAM] #app66/1
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
optimizer = adam
lr = 0.001
w_quantize = parametric_fp_b_xmax

[PARAMETRIC_FP_WQ_DELTA_B_INIT_ADAM] #app66/2
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
optimizer = adam
lr = 0.001
w_quantize = parametric_fp_d_b

[PARAMETRIC_FP_WAQ_DELTA_XMAX_INIT_ADAM] #app66/3
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
optimizer = adam
lr = 0.001
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu

[PARAMETRIC_FP_WAQ_B_XMAX_INIT_ADAM]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
optimizer = adam
lr = 0.001
w_quantize = parametric_fp_b_xmax
a_quantize = parametric_fp_b_xmax_relu

[PARAMETRIC_FP_WAQ_DELTA_B_INIT_ADAM]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
optimizer = adam
lr = 0.001
w_quantize = parametric_fp_d_b
a_quantize = parametric_fp_d_b_relu


########### PARAMETRIC FIXED-POINT QUANTIZATION (CONSTRAINED - LEARN RANGE = XILINX) ###########

[PARAMETRIC_FP_W2Q_B_XMAX_CON_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.03
w_quantize = parametric_fp_b_xmax
w_bitwidth = 2
w_bitwidth_min = 2
w_bitwidth_max = 2

[PARAMETRIC_FP_W2A4Q_B_XMAX_CON_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.03
w_quantize = parametric_fp_b_xmax
a_quantize = parametric_fp_b_xmax_relu
w_bitwidth = 2
w_bitwidth_min = 2
w_bitwidth_max = 2
a_bitwidth = 4
a_bitwidth_min = 4
a_bitwidth_max = 4


[PARAMETRIC_FP_W2Q_B_XMAX_CON_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_b_xmax
w_bitwidth = 2
w_bitwidth_min = 2
w_bitwidth_max = 2

[PARAMETRIC_FP_W2A4Q_B_XMAX_CON_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_b_xmax
a_quantize = parametric_fp_b_xmax_relu
w_bitwidth = 2
w_bitwidth_min = 2
w_bitwidth_max = 2
a_bitwidth = 4
a_bitwidth_min = 4
a_bitwidth_max = 4


[PARAMETRIC_FP_W2Q_B_XMAX_CON_INIT_RRLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_b_xmax
w_bitwidth = 2
w_bitwidth_min = 2
w_bitwidth_max = 2

[PARAMETRIC_FP_W2A4Q_B_XMAX_CON_INIT_RRLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_b_xmax
a_quantize = parametric_fp_b_xmax_relu
w_bitwidth = 2
w_bitwidth_min = 2
w_bitwidth_max = 2
a_bitwidth = 4
a_bitwidth_min = 4
a_bitwidth_max = 4


########### PARAMETRIC FIXED-POINT QUANTIZATION (CONSTRAINED - LEARN BOTH) ###########

[PARAMETRIC_FP_WQ_DELTA_XMAX_CON_INIT_OLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_d_xmax
target_weight_kbytes = 70.1

[PARAMETRIC_FP_WAMQ_DELTA_XMAX_CON_INIT_OLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.1
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
target_weight_kbytes = 70.1
target_activation_kbytes = 8.1
target_activation_type = max

[PARAMETRIC_FP_WASQ_DELTA_XMAX_CON_INIT_OLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.1
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
target_weight_kbytes = 70.1
target_activation_kbytes = 92.1
target_activation_type = sum


[PARAMETRIC_FP_WQ_DELTA_XMAX_CON_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_d_xmax
target_weight_kbytes = 70.1

[PARAMETRIC_FP_WAMQ_DELTA_XMAX_CON_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
target_weight_kbytes = 70.1
target_activation_kbytes = 8.1
target_activation_type = max

[PARAMETRIC_FP_WASQ_DELTA_XMAX_CON_INIT]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
target_weight_kbytes = 70.1
target_activation_kbytes = 92.1
target_activation_type = sum


[PARAMETRIC_FP_WQ_DELTA_XMAX_CON_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
target_weight_kbytes = 70.1

[PARAMETRIC_FP_WAMQ_DELTA_XMAX_CON_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
target_weight_kbytes = 70.1
target_activation_kbytes = 8.1
target_activation_type = max

[PARAMETRIC_FP_WASQ_DELTA_XMAX_CON_INIT_RLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
target_weight_kbytes = 70.1
target_activation_kbytes = 92.1
target_activation_type = sum

[PARAMETRIC_FP_WQ_DELTA_XMAX_CON_INIT_RLR2]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
target_weight_kbytes = 70.1
initial_cost_lambda2 = 0.1

[PARAMETRIC_FP_WAMQ_DELTA_XMAX_CON_INIT_RLR2]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_bitwidth = 6
target_weight_kbytes = 70.1
target_activation_kbytes = 8.1
target_activation_type = max
initial_cost_lambda2 = 0.1
initial_cost_lambda3 = 1.0

[PARAMETRIC_FP_WASQ_DELTA_XMAX_CON_INIT_RLR2]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_bitwidth = 6
target_weight_kbytes = 70.1
target_activation_kbytes = 92.1
target_activation_type = sum
initial_cost_lambda2 = 0.1
initial_cost_lambda3 = 1.0

[PARAMETRIC_FP_WQ_DELTA_XMAX_CON_INIT_RLR3]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
target_weight_kbytes = 70.1
initial_cost_lambda2 = 0.1

[PARAMETRIC_FP_WAMQ_DELTA_XMAX_CON_INIT_RLR3]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_bitwidth = 6
target_weight_kbytes = 70.1
target_activation_kbytes = 8.1
target_activation_type = max
initial_cost_lambda2 = 0.1
initial_cost_lambda3 = 1.0

[PARAMETRIC_FP_WASQ_DELTA_XMAX_CON_INIT_RLR3]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_bitwidth = 6
target_weight_kbytes = 70.1
target_activation_kbytes = 92.1
target_activation_type = sum
initial_cost_lambda2 = 0.1
initial_cost_lambda3 = 1.0

[PARAMETRIC_FP_WQ_DELTA_XMAX_CON_INIT_RLR4]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
target_weight_kbytes = 70.1
initial_cost_lambda2 = 0.1

[PARAMETRIC_FP_WAMQ_DELTA_XMAX_CON_INIT_RLR4]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_bitwidth = 6
target_weight_kbytes = 70.1
target_activation_kbytes = 8.1
target_activation_type = max
initial_cost_lambda2 = 0.1
initial_cost_lambda3 = 0.1

[PARAMETRIC_FP_WASQ_DELTA_XMAX_CON_INIT_RLR4]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_bitwidth = 6
target_weight_kbytes = 70.1
target_activation_kbytes = 92.1
target_activation_type = sum
initial_cost_lambda2 = 0.1
initial_cost_lambda3 = 0.1

[PARAMETRIC_FP_WQ_DELTA_XMAX_CON_INIT_RLR5]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
target_weight_kbytes = 70.1
initial_cost_lambda2 = 0.1

[PARAMETRIC_FP_WAMQ_DELTA_XMAX_CON_INIT_RLR5]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_bitwidth = 6
target_weight_kbytes = 70.1
target_activation_kbytes = 8.1
target_activation_type = max
initial_cost_lambda2 = 0.1
initial_cost_lambda3 = 1.0

[PARAMETRIC_FP_WASQ_DELTA_XMAX_CON_INIT_RLR5]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_bitwidth = 6
target_weight_kbytes = 70.1
target_activation_kbytes = 92.1
target_activation_type = sum
initial_cost_lambda2 = 0.1
initial_cost_lambda3 = 1.0

[PARAMETRIC_FP_WQ_DELTA_XMAX_CON_INIT_RLR6]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
target_weight_kbytes = 70.1
initial_cost_lambda2 = 0.1

[PARAMETRIC_FP_WAMQ_DELTA_XMAX_CON_INIT_RLR6]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_bitwidth = 6
target_weight_kbytes = 70.1
target_activation_kbytes = 8.1
target_activation_type = max
initial_cost_lambda2 = 0.1
initial_cost_lambda3 = 0.1

[PARAMETRIC_FP_WASQ_DELTA_XMAX_CON_INIT_RLR6]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.01
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
a_bitwidth = 6
target_weight_kbytes = 70.1
target_activation_kbytes = 92.1
target_activation_type = sum
initial_cost_lambda2 = 0.1
initial_cost_lambda3 = 0.1

[PARAMETRIC_FP_WQ_DELTA_XMAX_CON_INIT_RRLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_d_xmax
target_weight_kbytes = 70.1

[PARAMETRIC_FP_WAMQ_DELTA_XMAX_CON_INIT_RRLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
target_weight_kbytes = 70.1
target_activation_kbytes = 8.1
target_activation_type = max

[PARAMETRIC_FP_WASQ_DELTA_XMAX_CON_INIT_RRLR]
pretrain_dir=/home/yjm/D/yjm/mixed-precision-dnns-pytorch-data/DEFAULT/checkpoint.t7
lr = 0.003
w_quantize = parametric_fp_d_xmax
a_quantize = parametric_fp_d_xmax_relu
target_weight_kbytes = 70.1
target_activation_kbytes = 92.1
target_activation_type = sum



